{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORwbbyn1QuCb6IwzGT2G4G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edson-depaula/DIO_BairesDev_Bootcamp/blob/main/Projeto_Detec%C3%A7%C3%A3o_Facial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PRÉ-REQUISITOS E INSTALAÇÕES\n",
        "# =============================================================================\n",
        "\n",
        "# Instalar bibliotecas necessárias\n",
        "!pip install scikit-learn joblib keras-facenet mtcnn\n",
        "!pip install --upgrade lz4 # A linha que foi adicionada para garantir\n",
        "\n",
        "# Montar o Google Drive para acessar as imagens de treinamento\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =============================================================================\n",
        "# IMPORTS E FUNÇÕES AUXILIARES\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import joblib\n",
        "from keras_facenet import FaceNet\n",
        "from mtcnn import MTCNN\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, Javascript, Image\n",
        "from base64 import b64decode\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Definir o caminho para o seu projeto no Google Drive\n",
        "drive_path = '/content/drive/MyDrive/Projeto Reconhecimento Facial'\n",
        "dataset_path = drive_path\n",
        "\n",
        "def get_face_embedding(model, face_array):\n",
        "    \"\"\"Gera um embedding de 128 dimensões para uma face.\"\"\"\n",
        "    face_array = (face_array - face_array.mean()) / face_array.std()\n",
        "    face_expandida = np.expand_dims(face_array, axis=0)\n",
        "    embedding = model.model.predict(face_expandida)\n",
        "    return embedding[0]\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto() {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capturar';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      return new Promise((resolve) => {\n",
        "        capture.onclick = () => {\n",
        "          const canvas = document.createElement('canvas');\n",
        "          canvas.width = video.videoWidth;\n",
        "          canvas.height = video.videoHeight;\n",
        "          canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "          stream.getVideoTracks()[0].stop();\n",
        "          div.remove();\n",
        "          resolve(canvas.toDataURL('image/jpeg', %f));\n",
        "        };\n",
        "      });\n",
        "    }\n",
        "    '''.replace('%f', str(quality)))\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto()')\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n",
        "\n",
        "# Adicione esta importação no topo do seu script, se ainda não tiver\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Nova versão da função processar_e_mostrar_imagem\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def processar_e_mostrar_imagem(frame, svm_classifier, label_encoder, model_facenet, detector_de_faces):\n",
        "    \"\"\"Processa uma imagem e exibe o resultado com um limite de confiança.\"\"\"\n",
        "\n",
        "    # Detecção de faces com MTCNN\n",
        "    faces_detectadas = detector_de_faces.detect_faces(frame)\n",
        "    frame_copy = frame.copy() # Cria uma cópia para evitar modificações indesejadas\n",
        "\n",
        "    # Definir o limite de confiança\n",
        "    threshold_confianca = 0.75  # Este valor pode ser ajustado (de 0.0 a 1.0)\n",
        "\n",
        "    for face_info in faces_detectadas:\n",
        "        x, y, w, h = face_info['box']\n",
        "        face_recortada = frame_copy[y:y+h, x:x+w]\n",
        "\n",
        "        try:\n",
        "            face_redimensionada = cv2.resize(face_recortada, (160, 160))\n",
        "\n",
        "            # Gerar o embedding da face atual\n",
        "            embedding_da_face = get_face_embedding(model_facenet, face_redimensionada)\n",
        "            embedding_da_face = np.expand_dims(embedding_da_face, axis=0)\n",
        "\n",
        "            # Fazer a predição e obter as probabilidades\n",
        "            predicoes_prob = svm_classifier.predict_proba(embedding_da_face)[0]\n",
        "            label_predito = svm_classifier.predict(embedding_da_face)[0]\n",
        "\n",
        "            # Achar a maior probabilidade para a predição\n",
        "            probabilidade_max = np.max(predicoes_prob)\n",
        "\n",
        "            if probabilidade_max > threshold_confianca:\n",
        "                nome_da_pessoa = label_encoder.inverse_transform([label_predito])[0]\n",
        "            else:\n",
        "                nome_da_pessoa = \"Desconhecido\"\n",
        "\n",
        "            # Desenhar o retângulo e o nome\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, nome_da_pessoa, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar a face: {e}\")\n",
        "            pass\n",
        "\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "# =============================================================================\n",
        "# PARTE 1 e 2: EXTRAÇÃO, AUMENTO DE DADOS E TREINAMENTO (Versão estável)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Iniciando a extração de embeddings e o aumento de dados...\")\n",
        "model_facenet = FaceNet()\n",
        "detector_de_faces = MTCNN()\n",
        "embeddings = []\n",
        "nomes = []\n",
        "\n",
        "# Aumentar a quantidade de dados de treinamento com as fotos existentes\n",
        "for nome_pessoa in os.listdir(dataset_path):\n",
        "    caminho_pessoa = os.path.join(dataset_path, nome_pessoa)\n",
        "    if not os.path.isdir(caminho_pessoa): continue\n",
        "\n",
        "    print(f\"Processando e aumentando fotos de: {nome_pessoa}\")\n",
        "\n",
        "    # Carregar todas as fotos da pessoa\n",
        "    for nome_arquivo in os.listdir(caminho_pessoa):\n",
        "        caminho_imagem = os.path.join(caminho_pessoa, nome_arquivo)\n",
        "        imagem = cv2.imread(caminho_imagem)\n",
        "        if imagem is None: continue\n",
        "\n",
        "        # Encontrar e processar a face na imagem\n",
        "        faces_detectadas = detector_de_faces.detect_faces(imagem)\n",
        "        if len(faces_detectadas) > 0:\n",
        "            face_info = faces_detectadas[0] # Pega a primeira face\n",
        "            x, y, w, h = face_info['box']\n",
        "            face_recortada = imagem[y:y+h, x:x+w]\n",
        "\n",
        "            try:\n",
        "                face_redimensionada = cv2.resize(face_recortada, (160, 160))\n",
        "                embedding = get_face_embedding(model_facenet, face_redimensionada)\n",
        "                embeddings.append(embedding)\n",
        "                nomes.append(nome_pessoa)\n",
        "            except Exception as e:\n",
        "                print(f\"Não foi possível processar a imagem {nome_arquivo}: {e}\")\n",
        "\n",
        "embeddings = np.array(embeddings)\n",
        "nomes = np.array(nomes)\n",
        "\n",
        "print(f\"Total de embeddings extraídos: {len(embeddings)}\")\n",
        "print(\"Extração de embeddings concluída.\")\n",
        "\n",
        "# Treinamento do classificador\n",
        "print(\"\\nIniciando o treinamento do classificador...\")\n",
        "label_encoder = LabelEncoder()\n",
        "labels_numericas = label_encoder.fit_transform(nomes)\n",
        "svm_classifier = SVC(kernel='linear', probability=True)\n",
        "svm_classifier.fit(embeddings, labels_numericas)\n",
        "joblib.dump(svm_classifier, 'svm_classifier.joblib')\n",
        "joblib.dump(label_encoder, 'label_encoder.joblib')\n",
        "print(\"Treinamento do classificador concluído e modelos salvos.\")\n",
        "\n",
        "# =============================================================================\n",
        "# PARTE 3: RECONHECIMENTO POR IMAGEM (CAPTURA OU UPLOAD)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nModelos carregados. Escolha uma opção abaixo para o reconhecimento.\")\n",
        "\n",
        "# Carregar os modelos de predição\n",
        "svm_classifier = joblib.load('svm_classifier.joblib')\n",
        "label_encoder = joblib.load('label_encoder.joblib')\n",
        "model_facenet = FaceNet()\n",
        "detector_de_faces = MTCNN()\n",
        "\n",
        "# --- Opção 1: Capturar foto com a webcam ---\n",
        "print(\"\\nOpção 1: Clique no botão 'Capturar' abaixo para tirar uma foto com sua webcam.\")\n",
        "try:\n",
        "    filename = take_photo()\n",
        "    print(f'Foto salva em \"{filename}\"')\n",
        "\n",
        "    img = cv2.imread(filename)\n",
        "    processar_e_mostrar_imagem(img, svm_classifier, label_encoder, model_facenet, detector_de_faces)\n",
        "\n",
        "except Exception as err:\n",
        "    print(f\"Erro na Opção 1: {err}\")\n",
        "\n",
        "# --- Opção 2: Fazer upload de uma imagem ---\n",
        "print(\"\\nOpção 2: Clique no botão 'Choose Files' para fazer upload de uma imagem.\")\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        print(f'Uploaded file \"{filename}\"')\n",
        "        img = cv2.imread(filename)\n",
        "        processar_e_mostrar_imagem(img, svm_classifier, label_encoder, model_facenet, detector_de_faces)\n",
        "\n",
        "except Exception as err:\n",
        "    print(f\"Erro na Opção 2: {err}\")"
      ],
      "metadata": {
        "id": "7_yTPD0Ay_yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# BLOCO DE RECONHECIMENTO POR WEBCAM (APÓS O TREINAMENTO)\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import joblib\n",
        "from keras_facenet import FaceNet\n",
        "from mtcnn import MTCNN\n",
        "from google.colab import files, drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js  # A linha que faltava\n",
        "from base64 import b64decode\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# --- Funções Auxiliares Necessárias ---\n",
        "\n",
        "# Certifique-se de que o Drive está montado para carregar os modelos\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def get_face_embedding(model, face_array):\n",
        "    \"\"\"Gera um embedding de 128 dimensões para uma face.\"\"\"\n",
        "    face_array = (face_array - face_array.mean()) / face_array.std()\n",
        "    face_expandida = np.expand_dims(face_array, axis=0)\n",
        "    embedding = model.model.predict(face_expandida)\n",
        "    return embedding[0]\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto() {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capturar';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      return new Promise((resolve) => {\n",
        "        capture.onclick = () => {\n",
        "          const canvas = document.createElement('canvas');\n",
        "          canvas.width = video.videoWidth;\n",
        "          canvas.height = video.videoHeight;\n",
        "          canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "          stream.getVideoTracks()[0].stop();\n",
        "          div.remove();\n",
        "          resolve(canvas.toDataURL('image/jpeg', %f));\n",
        "        };\n",
        "      });\n",
        "    }\n",
        "    '''.replace('%f', str(quality)))\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto()')\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n",
        "\n",
        "def processar_e_mostrar_imagem(frame, svm_classifier, label_encoder, model_facenet, detector_de_faces):\n",
        "    \"\"\"Processa uma imagem e exibe o resultado com um limite de confiança.\"\"\"\n",
        "\n",
        "    faces_detectadas = detector_de_faces.detect_faces(frame)\n",
        "    frame_copy = frame.copy()\n",
        "\n",
        "    threshold_confianca = 0.75\n",
        "\n",
        "    for face_info in faces_detectadas:\n",
        "        x, y, w, h = face_info['box']\n",
        "        face_recortada = frame_copy[y:y+h, x:x+w]\n",
        "\n",
        "        try:\n",
        "            face_redimensionada = cv2.resize(face_recortada, (160, 160))\n",
        "\n",
        "            embedding_da_face = get_face_embedding(model_facenet, face_redimensionada)\n",
        "            embedding_da_face = np.expand_dims(embedding_da_face, axis=0)\n",
        "\n",
        "            predicoes_prob = svm_classifier.predict_proba(embedding_da_face)[0]\n",
        "            label_predito = svm_classifier.predict(embedding_da_face)[0]\n",
        "\n",
        "            probabilidade_max = np.max(predicoes_prob)\n",
        "\n",
        "            if probabilidade_max > threshold_confianca:\n",
        "                nome_da_pessoa = label_encoder.inverse_transform([label_predito])[0]\n",
        "            else:\n",
        "                nome_da_pessoa = \"Desconhecido\"\n",
        "\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, nome_da_pessoa, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar a face: {e}\")\n",
        "            pass\n",
        "\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "\n",
        "# --- Execução do Reconhecimento ---\n",
        "\n",
        "print(\"\\nCarregando modelos para reconhecimento...\")\n",
        "\n",
        "# Carregar os modelos de predição\n",
        "svm_classifier = joblib.load('svm_classifier.joblib')\n",
        "label_encoder = joblib.load('label_encoder.joblib')\n",
        "model_facenet = FaceNet()\n",
        "detector_de_faces = MTCNN()\n",
        "\n",
        "print(\"\\nModelos carregados. Clique no botão para tirar uma foto.\")\n",
        "try:\n",
        "    filename = take_photo()\n",
        "    print(f'Foto salva em \"{filename}\"')\n",
        "\n",
        "    img = cv2.imread(filename)\n",
        "    processar_e_mostrar_imagem(img, svm_classifier, label_encoder, model_facenet, detector_de_faces)\n",
        "\n",
        "except Exception as err:\n",
        "    print(f\"Erro ao capturar ou processar a foto: {err}\")"
      ],
      "metadata": {
        "id": "2FYQd_jyEsuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# BLOCO DE RECONHECIMENTO POR UPLOAD DE FOTO (APÓS O TREINAMENTO)\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import joblib\n",
        "from keras_facenet import FaceNet\n",
        "from mtcnn import MTCNN\n",
        "from google.colab import files, drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# --- Funções Auxiliares Necessárias ---\n",
        "\n",
        "# Certifique-se de que o Drive está montado para carregar os modelos\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def get_face_embedding(model, face_array):\n",
        "    \"\"\"Gera um embedding de 128 dimensões para uma face.\"\"\"\n",
        "    face_array = (face_array - face_array.mean()) / face_array.std()\n",
        "    face_expandida = np.expand_dims(face_array, axis=0)\n",
        "    embedding = model.model.predict(face_expandida)\n",
        "    return embedding[0]\n",
        "\n",
        "def processar_e_mostrar_imagem(frame, svm_classifier, label_encoder, model_facenet, detector_de_faces):\n",
        "    \"\"\"Processa uma imagem e exibe o resultado com um limite de confiança.\"\"\"\n",
        "\n",
        "    faces_detectadas = detector_de_faces.detect_faces(frame)\n",
        "    frame_copy = frame.copy()\n",
        "\n",
        "    # Utilize o threshold de confiança que você ajustou\n",
        "    threshold_confianca = 0.75\n",
        "\n",
        "    for face_info in faces_detectadas:\n",
        "        x, y, w, h = face_info['box']\n",
        "        face_recortada = frame_copy[y:y+h, x:x+w]\n",
        "\n",
        "        try:\n",
        "            face_redimensionada = cv2.resize(face_recortada, (160, 160))\n",
        "\n",
        "            embedding_da_face = get_face_embedding(model_facenet, face_redimensionada)\n",
        "            embedding_da_face = np.expand_dims(embedding_da_face, axis=0)\n",
        "\n",
        "            predicoes_prob = svm_classifier.predict_proba(embedding_da_face)[0]\n",
        "            label_predito = svm_classifier.predict(embedding_da_face)[0]\n",
        "\n",
        "            probabilidade_max = np.max(predicoes_prob)\n",
        "\n",
        "            if probabilidade_max > threshold_confianca:\n",
        "                nome_da_pessoa = label_encoder.inverse_transform([label_predito])[0]\n",
        "            else:\n",
        "                nome_da_pessoa = \"Desconhecido\"\n",
        "\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, nome_da_pessoa, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar a face: {e}\")\n",
        "            pass\n",
        "\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "\n",
        "# --- Execução do Reconhecimento ---\n",
        "\n",
        "print(\"\\nCarregando modelos para reconhecimento...\")\n",
        "\n",
        "# Carregar os modelos de predição\n",
        "svm_classifier = joblib.load('svm_classifier.joblib')\n",
        "label_encoder = joblib.load('label_encoder.joblib')\n",
        "model_facenet = FaceNet()\n",
        "detector_de_faces = MTCNN()\n",
        "\n",
        "print(\"\\nModelos carregados. Clique no botão 'Choose Files' para fazer upload de uma imagem.\")\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        print(f'Uploaded file \"{filename}\"')\n",
        "        img = cv2.imread(filename)\n",
        "        processar_e_mostrar_imagem(img, svm_classifier, label_encoder, model_facenet, detector_de_faces)\n",
        "\n",
        "except Exception as err:\n",
        "    print(f\"Erro ao fazer upload ou processar a foto: {err}\")"
      ],
      "metadata": {
        "id": "xOf7qh8oFiiC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}